{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fohRfLWTrwvB"
      },
      "source": [
        "# Step 1: Identify seed 0 and seed 1 pages for economic recovery functional network "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzXBxpEYrwvL"
      },
      "source": [
        "This approach does not rely on the existing knowledge graph. A functional graph based on page hit session data is created, before further filtering of the graph, to find a list of pages related to the economic recovery whole user journey (WUJ). \n",
        "\n",
        "The first step is to identify seed 0 and seed 1 pages. Seed 0 pages must be pre-defined and manually entered as `seed0_pages`. Using the GOV.UK mirror, `seed1_pages` are defined as pages linked from `seed0_pages`.\n",
        "\n",
        "ASSUMPTIONS: \n",
        "- A copy of the GOV.UK mirror is used from 23-04-2021. The topology sparse matrix therefore only includes page information (e.g.     page paths, hyperlinks on page paths) that is true on this date.\n",
        "- `seed0_pages` are defined as `/topic/further-education-skills` and `/browse/working/finding-job`. These were chosen as they are topic and browse pages, which therefore link to many similar pages. This analysis assumes these are important pages in the economic recovery whole user journey. `seed1_pages` are reliant on `seed0_pages`, therefore this analysis is dependent on the `seed0_pages` are.\n",
        "\n",
        "OUTPUT: \n",
        "- A topology sparse matrix of `seed0_pages` and `seed1_pages`: `topo_sparse_matrix_all_seeds` \n",
        "    - This is saved as a "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "z_KFNOrYrwvO"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "from googleapiclient.discovery import build\n",
        "import io\n",
        "import pickle\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlNZ7ggsw0vX"
      },
      "source": [
        "## Authentication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1MRQYG06tumw"
      },
      "outputs": [],
      "source": [
        "# authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_n-o8VPxG1R"
      },
      "source": [
        "## Create topology sparse matrix "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6rooHyBw2_J"
      },
      "source": [
        "Using a copy of the GOV.UK mirror from the 23-04-2021, a topology sparse matrix is created, where each row is a source url and each column is a destination url. A `1` indicates a hyperlink from the source to the destination url. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7Qnp74YRrwvR"
      },
      "outputs": [],
      "source": [
        "# import mirror topology matrix\n",
        "drive_service = build('drive', 'v3')\n",
        "file_id = '1oskKqx16S_jIo67-fMJk8WaCenQb6UFH'\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    # _ is a placeholder for a progress object that we ignore.\n",
        "    # (Our file is small, so we skip reporting progress.)\n",
        "    _, done = downloader.next_chunk()\n",
        "\n",
        "downloaded.seek(0)\n",
        "mirror_topology_matrix = pickle.load(downloaded)\n",
        "\n",
        "# import vertex\n",
        "file_id = '1bf9inTVhUygJNm1lgTs2pG87x1RiSfoU'\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "downloaded = io.BytesIO()\n",
        "downloader = MediaIoBaseDownload(downloaded, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    # _ is a placeholder for a progress object that we ignore.\n",
        "    # (Our file is small, so we skip reporting progress.)\n",
        "    _, done = downloader.next_chunk()\n",
        "\n",
        "downloaded.seek(0)\n",
        "vertex = pickle.load(downloaded)\n",
        "\n",
        "# combine mirror_topology matrix and vertex to create topology sparse matrix\n",
        "topo_sparse_matrix = pd.DataFrame.sparse.from_spmatrix(mirror_topology_matrix, index=vertex, columns=vertex)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6MlUitFxy_Q"
      },
      "source": [
        "## Define `seed0_pages` and `seed1_pages`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ntVewrVavEw0"
      },
      "outputs": [],
      "source": [
        "# Define seed0 pages \n",
        "seed0_pages = ['/topic/further-education-skills', '/browse/working/finding-job']\n",
        "\n",
        "# Only keep seed0 pages in topo_sparse_matrix (rows)\n",
        "topo_sparse_matrix_seed_0 = topo_sparse_matrix.loc[seed0_pages, :]\n",
        "\n",
        "# Define seed1 pages (pages that are hyperlinked from seed0)\n",
        "topo_sparse_matrix_all_seeds = topo_sparse_matrix_seed_0.loc[:, (topo_sparse_matrix_seed_0 != 0).any(axis=0)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67oTcJAJrwvT"
      },
      "outputs": [],
      "source": [
        "# Save a list of seed1 pages \n",
        "#seed1_pages = topo_sparse_matrix_all_seeds.columns.values.tolist()\n",
        "#seed1_pages\n",
        "df = pd.DataFrame(seed1_pages, columns=[\"colummn\"])\n",
        "df.to_csv('seed1_economic_recovery.csv', index=False)\n",
        "files.download('seed1_economic_recovery.csv')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "step_one_identify_seed_pages.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "c6313e0c8b41eb13583c36725f8a1f1fa69ba497bb7e6eaf409642bf47446516"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
